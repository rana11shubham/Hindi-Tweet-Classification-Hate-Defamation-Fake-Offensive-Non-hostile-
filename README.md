## Hindi Tweet Multi-Label Classification (Hate, Defamation, Fake, Offensive, Non-hostile)
# Introduction
Twitter is currently home to 22.1 million users in India. It is considered a valuable platform for companies to advertise their products and make users aware of their brand. Also, some companies use Twitter as a medium to provide support to their customers and receive valuable consumer feedback and suggestions to make their services better.It also serves as a great source of news. It not only acts as a powerful means of communication but also shapes the thinking of an individual. It is a flexible, open, and multi-use platform that grabs people’s attention all across the globe. However, Twitter serves as a residence for online abuse, hostile communication, defamation, and fake news. It is a matter of concern that needs special attention. Thus, there is a dire need to stop abusive, offensive, defamatory, and fake tweets on Twitter. It is crucial to identify all such tweets because not all negative tweets are hostile, harsh, or objectionable. So, now we are going to discuss about the Hindi tweet classification which is a potential solution to handle such a scenario and the various models that label Hindi tweets as offensive, hate, defamation, non-hostile or fake (multi-label classification) in order to achieve the main goal of controlling abusive tweets and fake news on Twitter (India).

# Motivation
In the recent Covid-19 pandemic situation, the people were restricted to their homes. The various social media platforms were the only hope for them to connect with each other and share information. During the lockdown, Twitter served as one of the virtual platforms to learn information about Covid-19. But, the false and misleading information on various social media often led to false beliefs and panic among the audience. Also, in 2018, Amnesty International, an organization that works for human rights, regarded Twitter as a “toxic place for women” based on its analysis of almost 15 million tweets. According to the findings of Amnesty International, it turned out that women using Twitter often become the target of online abuse. Online abuse in hostile tweets, troll messages, death, and rape threats primarily impact women’s mental health, making Twitter an unsafe and toxic place for women. As a result, this also affects the participation of women in keeping their views on Twitter. It also leads to an increase in levels of stress and anxiety among women who face online abuse. Twitter fails when it comes to racist abuse. Often black people suffer from racist abuse on Twitter. When Black English footballers lost to Italy in a UEFA European Football Championship, many racist tweets were made against the players. There is no doubt that social defamation can destroy one’s personal and professional relationships. Surprisingly, Twitter is one such social media platform where one can expect to find many defamation cases. Defamation cases and false statements made about a business or a person not only damages one’s reputation but also negatively impact one’s work life. It can make people lose their job and mental peace. All these points emphasize the need to identify such tweets so that the necessary actions can be taken to avoid any bad effects or outcomes. Hindi is the most commonly spoken language in India. Not much work has been previously done on Hindi tweet classification. Hence, this motivated us to build some models that will aid to achieve the main goal of controlling abusive tweets and fake news on Twitter (India).

# INSIGHTS ABOUT THE DATASET:
The dataset being used for this project is taken from the CONSTRAINT 2021 contest. The Training set, Validation set, and Test set all are taken from CONSTRAINT 2021. The given dataset consisted of tweets, and the multi-class labels suggesting whether the tweet is fake, hate, offensive, defamation, or nonhostile. Out of the total 8192 tweets, 4358 belong to the non-hostile class, while the rest 3834 tweets belong to one of the hostile dimensions. For the hostile dimensions,1136 belong to hate, 1064 to offensive, 810 to defamation, and 1638 tweets belong to the fake class. On analysing the dataset, we observed that the samples were evenly distributed between the classes and there was no class imbalance. The brief statistics of the dataset are shown in Figure 1. Also, it was observed that the tweets which were labelled as ‘real’ were of longer length than the tweets which were labelled as ‘fake’. The mean length of the real tweets is around 215 characters while the mean length of the fake tweets is around 144 characters. This has been pictorially represented in the Figure 2. It was found that there are many similar words in all the class labels. Words like ‘देश’, ‘भारत’, ‘मोदी’, ‘सरकार are being used in the majority of the tweets. The most frequent words in the hostile tweets and the non-hostile tweets have been shown in Figure 3 and Figure 4 respectively.
Here are the meanings of the labels assigned to a tweet:
* Offensive: Offensive tweets are those which try to insult a person or a business using disrespectful, hurtful and rude words.
* Hate: Hate tweets are those which show hatred towards a person or a specific group on the grounds of their race, religious beliefs, etc.
* Defamation: Defamation tweets are those which try to destroy/damage the reputation of an individual or a group in public.
* Fake: Fake tweets are those which are false or not genuine.
* Non-hostile: Non-hostile tweets are those which do not involve any hostility.
!@!@!@!figure
# METHODOLOGY USED:
## DATASET PREPROCESSING:
Data pre-processing is done prior to training the models. It is a crucial step because it cleans the data to make it useful. Also the performance of the models on the clean data is good. The phases in pre-processing of tweets are shown in Figure 6.
All the URL links starting with either https or www and all the mentions using @ were removed from the tweets since they do not have any role in deciding the nature of the tweets. All the characters other than Devanagari characters were removed because they are not a part of Hindi language. Also, all the special characters were removed because they are not important in deciding the nature of the tweet. All the emojis were removed because they are not text. Also, all the commonly used words known as stop words of Hindi language were removed. Tokenization was performed in which each Hindi tweet was broken down into the words it contains also known as tokens. The most frequently occurring words in the dataset were removed since they do not impact the classification of the tweets. We have drawn the word cloud for non-hostile and hostile tweets for the pictorial representation of the most frequent words. This representation can be seen in Figure 5. Stemming was done to reduce each token into its base form or the stem form. Stratification was performed to create a separate column for each of the unique label. For each Hindi tweet, one was inserted under those columns which corresponded to the labels of the respective tweet.

## FEATURE EXTRACTION:
Feature extraction is the process of extraction of numerical features from the textual data which are Hindi Tweets in our case. It comprises of some steps.The first step is known as Tokenization. The second step is Counting in which the count for each token in the dataset is computed.The third step is Normalization in which no emphasis is given on the tokens with very high or very low count since such words can affect the accuracy of the model.
### Text Data into Numerical Vectors:
* Count Vectorizer is the normalization technique in which it first creates the list of vocabulary or features based on the whole dataset. Now, it stores the frequency of each feature for each of the instances regardless of the importance of the features.
* TF-IDF(Term Frequency — Inverse Document Frequency is used to find the importance of the features. It first builds the list of vocabulary by applying specific rules, and then it finds the TF-IDF values for each of the words in the vocabulary of each of the instances in the dataset.TF stands for Term Frequency.TF for a token is computed as the ratio of its count in the document and the total number of tokens in the document. Higher the term frequency for a token , higher is its weight . Note, that term frequency gives an equal amount of weightage to each token in the document but there are tokens having very high count in the document but carry not much importance.IDF stands for the Inverse Document Frequency and is used to reduce the weightage of the tokens having high count while enhancing the weightage of the tokens having low count.IDF for a token is computed as the ratio of total number of documents and the total number of documents in which the token is present. Thus, IDF is low for a token having high count and high for a token having low count.
* Word2Vec Embedding: Each tweet in the dataset is broken down into tokens (words) using the space between them as a separator. A list of all the tokens is created. The Word2Vec class is feeded with the list of all tweets and a model is created. The created Word2Vec model is now trained on all the tweets for a number of epochs(10). Now , the trained model is used to obtain the word vector of each word in every tweet. The average of all the word vectors of all the words present in a tweet is computed and it acts as the single vector representation of that tweet. The single vector representation is found for each tweet in the dataset in the same manner.
* RNN is a neural network model which several layers along with hidden layers to perform the sentiment analysis in our case. We have used Keras embedding to convert the sentences into a group of vectors, and after that, we have trained this group of vectors on the RNN model in which we have used ’sigmoid’ as an activation function. We have also used different classification models with a one vs rest approach to classifying the multilabel tweets in the same embedding.
* Multilingual Bert (M-Bert) extends the Bert model that Google developed. It provides the word embedding for 104 different languages; Hindi is one of them. It gives the pre-trained model for word embedding to generate the vectors for the words. We have used the Hindi Electra model, which is a small model and has comparable results with the M-Bert model. We have fine-tuned the model and adjusted the learning rate to get better results. After getting the embedding for tweets, we have used several classification models on this embedding matrix and used one vs rest classification.
# BASELINE MODELS USED: 
The above-mentioned techniques performance was evaluated against some standard Machine Learning models like Decision Trees, Logistic Regression, SVM. The classification models were trained using the features extracted by the TF-IDF and Count-Vectorizer. The models were evaluated using the weighted F1 score.
* Decision Tree Classifier </br>
We have used hyper-parameters as: Max_depth=20, criterion=’gini’, class_weight=’balanced’.</br>
F1-score using Decision Tree Classifier on Test Set using RNN embedding : 0.724 </br>
F1-score using Decision Tree Classifier on Test Set using Word2Vec : 0.794 </br>
F1-score using Decision Tree Classifier on Test Set using M-Bert : 0.776 </br>
* SVM classifier </br>
We have used hyper-parameters as: kernel=rbf, C=0.01, gamma=1, class_weight=’balanced’.</br> 
F1-score using SVM Classifier on Test Set using RNN embedding : 0.57 </br>
F1-score using SVM Classifier on Test Set using Word2Vec : 0.698 </br>
F1-score using SVM Classifier on Test Set using M-Bert : 0.688 </br>
* Logistic Regression Classifier </br>
We have used hyper-parameters as: penalty=L2, solver=lib-linear, class_weight=’balanced’. </br>
F1-score using Logistic Regression Classifier on Test Set using RNN embedding : 0.572 </br>
F1-score using Logistic Regression Classifier on Test Set using Word2Vec : 0.760 </br>
F1-score using Logistic Regression Classifier on Test Set using M-Bert : 0.696 </br>
* Random Forest Classifier </br>
We have used hyper-parameters as: n-estimator=400, class_weight=’balanced’. </br>
F1-score using Random Forest Classifier on Test Set using RNN embedding : 0.718 </br>
F1-score using Random Forest Classifier on Test Set using Word2Vec : 0.820 </br>
F1-score using Random Forest Classifier on Test Set using M-Bert : 0.884 </br>
* LSTM </br>
We have used LSTM and bi-directional LSTM with activation function as sigmoid and found the following results in terms of accuracy: </br>
LSTM:- Accuracy = 77.8% </br>
Bi-directional LSTM:- Accuracy = 85.6% </br>

# RESULTS:
Several models which we used for classification are discussed below. Evaluation metric used to calculate the performance of the model is Weighted F1-Score.

# CONCLUSION:
This article concludes that M-Bert with random forest classifier outperformed RNN, Word2vec and LSTM with different models. With M-Bert and random forest classifier, we got the highest weighted F1-score = 0.884. For M-Bert, we have used the ”Hindi Electra Model”, it is very lightweight and is pre-trained on a vast corpus of data and works well on low memory. However, Word2Vec and LSTM models also performed significantly good.

# FUTURE WORK:
Tweet analysis for Non-hostile and hostile such as fake, defamation, hate and offensive news detection has a lot of scopes and is becoming more prevalent these days. On a larger scale, this paper’s idea can be used to classify the multi-label comments on various social media platforms such as Instagram, Twitter, Facebook, etc., especially for the Hindi language, as it is becoming more prevalent.
# CONTRIBUTION:
* Akash Rawat: Exploratory data analysis, data pre-processing, and implemented LSTM.
* Parul Sikri: Parul Sikri: Baseline model, RNN and Word2vec implementation.
* Shubham Rana: Literature Survey, Baseline model, and M-Bert implementation.
